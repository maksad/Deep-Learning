{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4994944eda42dc6616b553125e66a8f2",
     "grade": false,
     "grade_id": "cell-e927f5b226d8820f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 3. Part 2. Hyperparameter search\n",
    "\n",
    "## Learning goals\n",
    "* Practical experience in tuning hyperparameters of neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d35ce4a4160dc766d5dafef6587df43",
     "grade": false,
     "grade_id": "cell-deb06164b659c10e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Select data directory\n",
    "import os\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94a73c61cfb1c981c78c190a04afdd0",
     "grade": false,
     "grade_id": "cell-248e4ecd9a43eb69",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device which you are going to use for training\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "874062d2bb88959790dcf82b1e84f37d",
     "grade": false,
     "grade_id": "cell-839f6b565bcf4fc3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79f6c3886e7e58642ab3557c86554e87",
     "grade": false,
     "grade_id": "cell-2f05b92d3a6c0d86",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Grid search\n",
    "\n",
    "Your first task is to implement grid search in the cell below. You are allowed to use only modules imported in the previos cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e0c175dcc66de17b89f324ff1922a26",
     "grade": false,
     "grade_id": "cell-7f8b0904d5f32a5d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(*iterables):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      iterables: Each iterable is, e.g., a list (tuple or a numpy arrrays) containing grid values\n",
    "                  for one of the tuned parameter.\n",
    "    \n",
    "    Returns:\n",
    "      An iterator over all combinations of the grid values of the given iterables.\n",
    "      Each object returned by the iterator is a tuple whose i-th element is one of the grid values from the\n",
    "      i-th input iterable.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ddb43ee66296ff1207cddf895ba0d7e",
     "grade": true,
     "grade_id": "grid_search",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's test your implementation\n",
    "param1 = [0.1, 0.2, 0.3]  # Iterable with grid values of parameter 1\n",
    "param2 = [0.4, 0.5]       # Iterable with grid values of parameter 2\n",
    "param3 = [0.6, 0.7, 0.8]  # Iterable with grid values of parameter 3\n",
    "for i in grid_search(param1, param2, param3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91d274926876fcb5616dcf43b264bdf0",
     "grade": false,
     "grade_id": "cell-069f4b347dcccf90",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Random search\n",
    "\n",
    "Your second task is to implement random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddd2d450451c994d86c0bec211e722ef",
     "grade": false,
     "grade_id": "cell-b16dd20ed61841c0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def random_search(n, *param_ranges):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      n (int):      Number of hyperparameter combinations to be generated.\n",
    "      param_ranges: Each of the given arguments must be a list [`low`, `high`] where low\n",
    "                     defines the `lower` and `high` defines the upper boundaries of the sampling interval\n",
    "                     for the corresponding parameter.\n",
    "    Returns:\n",
    "      An iterator over n combinations of the hyperparameters. Each hyperparameter value is drawn uniformly\n",
    "      from interval [low, high] specified by the corresponding input argument.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f010d0f523297d534fc8e031a5295d2",
     "grade": true,
     "grade_id": "random_search",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n = 10  # Number of hyperparameter combinations\n",
    "param_range1 = [0.1, 0.9]  # lower and upper boundaries for parameter 1 \n",
    "param_range2 = [1.1, 1.9]  # lower and upper boundaries for parameter 2\n",
    "param_range3 = [2.1, 2.9]  # lower and upper boundaries for parameter 3\n",
    "for i in random_search(n, param_range1, param_range2, param_range3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cde47a7132e04ac2aa27eddb14ab45a",
     "grade": false,
     "grade_id": "cell-319b46cfefe56de9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Hyperparameter search on a small dataset\n",
    "\n",
    "Let us tune the hyperparameters of an MLP network to classify wines from the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60fd0fc5824fc8536ebed0509c9b8fbf",
     "grade": false,
     "grade_id": "cell-e97f1b93aae4eb89",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_dir = os.path.join(course_data_dir, 'winequality')\n",
    "print('Data loaded from %s' % data_dir)\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_csv(os.path.join(data_dir, 'winequality-red.csv'), delimiter=';'),\n",
    "    pd.read_csv(os.path.join(data_dir, 'winequality-white.csv'), delimiter=';')\n",
    "])\n",
    "\n",
    "x = df.loc[:, df.columns != 'quality'].values\n",
    "y = df['quality'].values >= 7  # Convert to a binary classification problem\n",
    "\n",
    "# Split into training, validation and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1, shuffle=True)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b9adc8f0ffc40389084cd7a7c44cd20",
     "grade": false,
     "grade_id": "cell-af76993a88f117c0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Scaling to zero mean and unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a7c904c922c7231f66e6ca3716c895e",
     "grade": false,
     "grade_id": "cell-dbbe7f34db4b2bfe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# We will use an MLP with two hidden layers and dropout\n",
    "n_inputs = 11\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, sizes, p=0):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(sizes[0], sizes[1]),\n",
    "            nn.Dropout(p),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(sizes[1], sizes[2]),\n",
    "            nn.Dropout(p),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(sizes[2], sizes[3])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "597762c204e06d85aabd9c64cb356df3",
     "grade": false,
     "grade_id": "cell-f6060297287321f8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute accuracy of a trained MLP on a given dataset\n",
    "def compute_accuracy(x_test_scaled, y_test, mlp):\n",
    "    mlp.eval()\n",
    "    x = torch.tensor(x_test_scaled, dtype=torch.float, device=device)\n",
    "    outputs = mlp.forward(x)\n",
    "    logits = outputs.cpu().data.numpy()\n",
    "    pred_test = logits.argmax(axis=1)\n",
    "    test_accuracy = accuracy_score(pred_test, y_test)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e7b69d8a13a714e7f436e96a468d31b",
     "grade": false,
     "grade_id": "cell-d128292281c38c47",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "def train(x_train_scaled, y_train, mlp, lrate, print_every):\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=lrate)\n",
    "    scheduler = StepLR(optimizer, step_size=20, gamma=0.95)\n",
    "    \n",
    "    n_epochs = 1000\n",
    "\n",
    "    train_accuracy_history = []\n",
    "    val_accuracy_history = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        mlp.train()\n",
    "        scheduler.step()\n",
    "        x = torch.tensor(x_train_scaled, device=device, dtype=torch.float)\n",
    "        y = torch.tensor(y_train.astype(int), device=device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp.forward(x)\n",
    "        loss = F.cross_entropy(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch % print_every) == 0:\n",
    "            # Store the progress of training\n",
    "            with torch.no_grad():\n",
    "                logits = outputs.cpu().data.numpy()\n",
    "                pred_train = logits.argmax(axis=1)\n",
    "                train_accuracy = accuracy_score(pred_train, y_train)\n",
    "                train_accuracy_history.append(train_accuracy)\n",
    "                \n",
    "                # Compute validation accuracy\n",
    "                val_accuracy = compute_accuracy(x_val_scaled, y_val, mlp)\n",
    "                val_accuracy_history.append(val_accuracy)\n",
    "                print('Train Epoch {}: Loss: {:.6f} Train accuracy {:.2f} Valdation accuracy {:.2f}'.format(\n",
    "                    epoch, loss.item(), train_accuracy, val_accuracy))\n",
    "    \n",
    "    return mlp, train_accuracy_history, val_accuracy_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6862ce1391cc94c3fee62e0e0738cff",
     "grade": false,
     "grade_id": "cell-a746f8a12e118f4f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let us tune the hyperparameters using our own implementation of random search. Try at least 10 parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbcb5acc5522003c859c9547ff37e766",
     "grade": false,
     "grade_id": "cell-ab668c4f56afd61e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n = 10  # Number of parameter combinations\n",
    "\n",
    "n_hidden1_range = [10, 400]\n",
    "h_hidden2_range = [10, 400]\n",
    "log_lrate_range = [np.log(0.001), np.log(0.1)]\n",
    "log_dropout_range = [np.log(0.001), np.log(0.3)]\n",
    "\n",
    "hyperparameters = []\n",
    "accuracies = []\n",
    "if not skip_training:\n",
    "    for (n_hidden1, n_hidden2, log_lrate, log_dropout) in \\\n",
    "            random_search(n, n_hidden1_range, h_hidden2_range, log_lrate_range, log_dropout_range):\n",
    "        n_hidden1, n_hidden2 = int(n_hidden1), int(n_hidden2)\n",
    "        lrate, dropout = np.exp(log_lrate), np.exp(log_dropout)\n",
    "        hyperparameters.append([n_hidden1, n_hidden2, lrate, dropout])\n",
    "        print('Hyperparameters: ', hyperparameters[-1])\n",
    "        mlp = MLP([n_inputs, n_hidden1, n_hidden2, 2], p=dropout)\n",
    "        print(mlp)\n",
    "        mlp.to(device)\n",
    "        mlp, train_accuracy_history, val_accuracy_history = train(x_train_scaled, y_train, mlp, lrate, print_every=199)\n",
    "        accuracies.append(val_accuracy_history[-1])\n",
    "        print('Final accuracy:', accuracies[-1])\n",
    "        #print(compute_accuracy(x_test_scaled, y_test, mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5c94a46ba3eff97234d62e87660aa57",
     "grade": false,
     "grade_id": "cell-40620bbbccd150cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = np.array(hyperparameters)\n",
    "accuracies = np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea65d13825bc256902124dae4f093ad",
     "grade": true,
     "grade_id": "rs_results_save",
     "locked": true,
     "points": 0.001,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save results to disk. Submit file `3_random_search.npz` together with your notebook.\n",
    "hs_filename = '3_random_search.npz'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the results of hyperparameter search (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            np.savez(hs_filename,\n",
    "                     hyperparameters=hyperparameters,\n",
    "                     accuracies=accuracies)\n",
    "            print('Results saved to %s' % hs_filename)\n",
    "        else:\n",
    "            print('Results not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
    "else:\n",
    "    rs = np.load(hs_filename)\n",
    "    hyperparameters = rs['hyperparameters']\n",
    "    accuracies = rs['accuracies']\n",
    "    print('Results loaded from %s' % hs_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bbc62aa874a18826fc908f57165a678",
     "grade": true,
     "grade_id": "cell-9afe65ee25eef472",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print results\n",
    "print('#hidden1 #hidden2 lrate dropout accuracy')\n",
    "ix = accuracies.argsort()[-1::-1]\n",
    "for (n_hidden1, n_hidden2, lrate, dropout), accuracy in zip(hyperparameters[ix], accuracies[ix]):\n",
    "    print('%8d %8d %5.3f %7.3f %8.3f' % (n_hidden1, n_hidden2, lrate, dropout, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53fa45df9a06d0987d1b373a50319f5a",
     "grade": false,
     "grade_id": "cell-dc6b17a7edcc98e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Train the network with the best hyperparameters including validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03698ac45dd63a7e17942ee7d8e14e3a",
     "grade": true,
     "grade_id": "rs_results",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Select hyperparameters producing the best validation accuracy\n",
    "best_run = accuracies.argmax()\n",
    "n_hidden1, n_hidden2, lrate, dropout = hyperparameters[best_run]\n",
    "sizes = [n_inputs, int(n_hidden1), int(n_hidden2), 2]\n",
    "mlp = MLP(sizes, p=dropout)\n",
    "mlp.to(device)\n",
    "print('Best architecture:', mlp)\n",
    "print('Best validataion accuracy: %.3f' % accuracies[best_run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5a944fb88a8a8685f2ae420fe4c99d9",
     "grade": false,
     "grade_id": "cell-9d49b9f61dd19efa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train the network with the best hyperparameters using also validation data\n",
    "if not skip_training:\n",
    "    mlp, train_accuracy_history, val_accuracy_history = train(\n",
    "        np.vstack((x_train_scaled, x_val_scaled)), np.hstack((y_train, y_val)),\n",
    "        mlp, lrate, print_every=199\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39d148c6e023b4ff72ee03a4a93afbeb",
     "grade": false,
     "grade_id": "cell-185608091d95bedf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the network to a file, submit this file together with your notebook\n",
    "filename = '3_mlp.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(mlp.state_dict(), filename)\n",
    "            print('Model saved to %s' % filename)\n",
    "        else:\n",
    "            print('Model not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=False.')\n",
    "else:\n",
    "    mlp.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    mlp.to(device)\n",
    "    print('Model loaded from %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "857542900ad66047fbf6ea6f9da3d054",
     "grade": true,
     "grade_id": "rs_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test the accuracy of the network trained with the best hyperparameters\n",
    "mlp.eval()\n",
    "test_accuracy = compute_accuracy(x_test_scaled, y_test, mlp)\n",
    "print(\"Test accuracy of the best model: %.3f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e841c5ad9ad25170b79f699a4cb3770",
     "grade": false,
     "grade_id": "cell-6b7ddbac12776f69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The accuracy should be greater than 0.85."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
