{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3cef3963a310e8bc9e86b71e08ebc0c",
     "grade": false,
     "grade_id": "cell-440df6cfa709812f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 4. Convolutional networks\n",
    "\n",
    "## Part 3. ResNet\n",
    "\n",
    "In the third part you need to train a convolutional neural network with a ResNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b0b185c50941111bc63f11990e412ab",
     "grade": false,
     "grade_id": "cell-e7fb713b137e5e3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "# Select data directory\n",
    "import os\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e0d4635b5905e98963ce92fbfb03375",
     "grade": false,
     "grade_id": "cell-d1a0f2d597ac9692",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d33ffe246f5459117f53cac15b370d",
     "grade": false,
     "grade_id": "cell-fe95dcf02c6b9c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05dae4d3d681cf9666b90ac940628a83",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in ../data/fashion_mnist\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(course_data_dir, 'fashion_mnist')\n",
    "print('Data stored in %s' % data_dir)\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9515e202d9b9f214b97032c7fc387cd2",
     "grade": false,
     "grade_id": "cell-7236520c2892e5d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a80a64994305fafe9250c409a26e2fbd",
     "grade": false,
     "grade_id": "cell-e505c3b987b78603",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## ResNet\n",
    "\n",
    "Let us train a network with an architecure inspired by [ResNet](https://arxiv.org/pdf/1512.03385.pdf).\n",
    "\n",
    "### ResNet block\n",
    "Our ResNet consists of blocks with two convolutional layers and a skip connection.\n",
    "\n",
    "In the most general case, our implementation should have:\n",
    "\n",
    "<img src=\"resnet_block_04.png\" width=220 style=\"float: right;\">\n",
    "\n",
    "* Two convolutional layers with:\n",
    "    * 3x3 kernel\n",
    "    * no bias terms\n",
    "    * padding with one pixel on both sides\n",
    "    * 2d batch normalization after each convolutional layer.\n",
    "\n",
    "* **The first convolutional layer also (optionally) has:**\n",
    "    * different number of input channels and output channels\n",
    "    * change of the resolution with stride.\n",
    "\n",
    "* The skip connection:\n",
    "    * simply copies the input if the resolution and the number of channels do not change.\n",
    "    * If either the resolution or the number of channels change, the skip connection should have one convolutional layer with:\n",
    "        * 1x1 convolution\n",
    "        * change of the resolution with stride (optional)\n",
    "        * different number of input channels and output channels (optional)\n",
    "    * If either the resolution or the number of channels change, the 1x1 convolutional layer is followed by 2d batch normalization.\n",
    "\n",
    "* The ReLU nonlinearity is applied after the first convolutional layer and at the end of the block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc44ddc69f370f1b5f1d68c0dfb0732f",
     "grade": false,
     "grade_id": "cell-0db2cc6de47fa70d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"resnet_blocks_123.png\" width=650 style=\"float: top;\">\n",
    "\n",
    "The implementation should also handle specific cases such as:\n",
    "\n",
    "Left: The number of channels and the resolution do not change.\n",
    "There are no computations in the skip connection.\n",
    "\n",
    "Middle: The number of channels changes, the resolution does not change.\n",
    "\n",
    "Right: The number of channels does not change, the resolution changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c970ca322994ba8941f555de4baf9b5",
     "grade": false,
     "grade_id": "cell-7c95703d5b7fa14c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Your task is to implement this block. You should use the implementations of layers in `nn.Conv2d`, `nn.BatchNorm2d` as the tests rely on those implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d38adfbfa37edfb193033cf63136c4e",
     "grade": false,
     "grade_id": "cell-5694742fd919140f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          in_channels (int):  Number of input channels.\n",
    "          out_channels (int): Number of output channels.\n",
    "          stride (int):       Controls the stride.\n",
    "        \"\"\"\n",
    "        super(Block, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            padding=1,\n",
    "            stride=stride,\n",
    "            bias=False, \n",
    "        )\n",
    "        self.batch1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            padding=1,\n",
    "            stride=1,\n",
    "            bias=False, \n",
    "        )\n",
    "        self.batch2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.skip_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            padding=0,\n",
    "            stride=stride,\n",
    "            bias=False\n",
    "        )\n",
    "        self.skip_batch = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.skip = False\n",
    "        if stride > 1 or in_channels != out_channels:\n",
    "            self.skip = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        skip_conv = x.clone()\n",
    "        x = self.relu(self.batch1(self.conv1(x)))\n",
    "        x = self.relu(self.batch2(self.conv2(x)))\n",
    "        if self.skip:\n",
    "            skip_conv = self.skip_batch(self.skip_conv(skip_conv))\n",
    "        return self.relu(x.add(skip_conv))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e38a695cc58c087fb944435b432e76",
     "grade": true,
     "grade_id": "block",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes seem to be ok.\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation of the Block\n",
    "\n",
    "# The number of channels and resolution do not change\n",
    "batch_size = 20\n",
    "x = torch.zeros(batch_size, 16, 28, 28)\n",
    "block = Block(in_channels=16, out_channels=16)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 16, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "# Increase the number of channels\n",
    "block = Block(in_channels=16, out_channels=32)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 32, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "# Decrease the resolution\n",
    "block = Block(in_channels=16, out_channels=16, stride=2)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 16, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "# Increase the number of channels and decrease the resolution\n",
    "block = Block(in_channels=16, out_channels=32, stride=2)\n",
    "y = block(x)\n",
    "assert y.shape == torch.Size([batch_size, 32, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes seem to be ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53ed1ca9da16198ce7eb9a79db3efce7",
     "grade": true,
     "grade_id": "block_relus",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a cell used for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51b00d6afb30e112db879c4c22150b81",
     "grade": true,
     "grade_id": "block_batch_norm",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a cell used for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c1c1c641143426800b594ba413f0bb0",
     "grade": false,
     "grade_id": "cell-0162fb4406cb8e15",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Group of blocks\n",
    "\n",
    "ResNet consists of several groups of blocks. The first block in a group may change the number of channels (often multiples the number by 2) and subsample (using strides).\n",
    "\n",
    "<img src=\"resnet_group.png\" width=500 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e619dcb4f94df39e95c1c84b81cd3165",
     "grade": false,
     "grade_id": "cell-b1930fef0ab076c3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us implement a group of blocks in this cell\n",
    "class GroupOfBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_blocks, stride=1):\n",
    "        super(GroupOfBlocks, self).__init__()\n",
    "\n",
    "        first_block = Block(in_channels, out_channels, stride)\n",
    "        other_blocks = [Block(out_channels, out_channels) for _ in range(1, n_blocks)]\n",
    "        self.group = nn.Sequential(first_block, *other_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.group(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ae5fb47e1118b4873e93d55ed8b1c9e",
     "grade": false,
     "grade_id": "cell-7481f327aee03c38",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupOfBlocks(\n",
      "  (group): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_conv): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skip_batch): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_conv): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skip_batch): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_conv): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (skip_batch): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Let's test it\n",
    "group = GroupOfBlocks(in_channels=10, out_channels=20, n_blocks=3)\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "506af15e210ba69d4fed34ed84c83234",
     "grade": false,
     "grade_id": "cell-71e97cde35d51918",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### ResNet\n",
    "\n",
    "Let us mplement a ResNet with the following architecture. It contains three groups of blocks, each group having two basic blocks.\n",
    "\n",
    "<img src=\"resnet.png\" width=900 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77bf6669d082870ffbbed40729d33bae",
     "grade": false,
     "grade_id": "cell-f0c465ad6f77bfc9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The cell below contains the implementation of all the layers except for the groups of blocks. Your task is to insert the groups of blocks in the middle.\n",
    "\n",
    "Note:\n",
    "* The number of channels in the second block should be double the number of channels in the first block, the number of channels in the third block should be four times the number of channels in the first block.\n",
    "* The second and the third block should reduce the resolution by `stride=2`, as shown in the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4887634d368b55faf02954f91902e2fd",
     "grade": false,
     "grade_id": "cell-b44918fa89e59c40",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_blocks, n_channels=64, num_classes=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_blocks (list):   A list with three elements which contains the number of blocks in \n",
    "                             each of the three groups of blocks in ResNet.\n",
    "                             For instance, n_blocks = [2, 4, 6] means that the first group has two blocks,\n",
    "                             the second group has four blocks and the third one has six blocks.\n",
    "          n_channels (int):  Number of channels in the first group of blocks.\n",
    "          num_classes (int): Number of classes.\n",
    "        \"\"\"\n",
    "        assert len(n_blocks) == 3, \"The number of groups should be three.\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.group1 = GroupOfBlocks(n_channels, 2*n_channels, n_blocks[0])\n",
    "        self.group2 = GroupOfBlocks(2*n_channels, 4*n_channels, n_blocks[1], stride=2)\n",
    "        self.group3 = GroupOfBlocks(4*n_channels, 4*n_channels, n_blocks[2], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4, stride=1)\n",
    "        self.fc = nn.Linear(4*n_channels, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose: print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        if verbose: print('conv1:  ', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        if verbose: print('bn1:    ', x.shape)\n",
    "        x = self.relu(x)\n",
    "        if verbose: print('relu:   ', x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        if verbose: print('maxpool:', x.shape)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        x = self.group1(x)\n",
    "        x = self.group2(x)\n",
    "        x = self.group3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if verbose: print('avgpool:', x.shape)\n",
    "\n",
    "        x = x.view(-1, self.fc.in_features)\n",
    "        if verbose: print('x.view: ', x.shape)\n",
    "        x = self.fc(x)\n",
    "        if verbose: print('out:    ', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bceef5e14b8945c01ec62757eb7f043",
     "grade": false,
     "grade_id": "cell-bae324fd2f70f08e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "conv1:   torch.Size([32, 10, 28, 28])\n",
      "bn1:     torch.Size([32, 10, 28, 28])\n",
      "relu:    torch.Size([32, 10, 28, 28])\n",
      "maxpool: torch.Size([32, 10, 14, 14])\n",
      "avgpool: torch.Size([32, 40, 1, 1])\n",
      "x.view:  torch.Size([32, 40])\n",
      "out:     torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "The shapes to be ok.\n"
     ]
    }
   ],
   "source": [
    "# Create a network with 2 block in each of the three groups\n",
    "n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "net = ResNet(n_blocks, n_channels=10)\n",
    "net.to(device)\n",
    "\n",
    "# Feed a batch of images from the training data to test the network\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.to(device)\n",
    "    print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "    y = net.forward(images, verbose=True)\n",
    "    print(y.shape)\n",
    "    assert y.shape == torch.Size([32, 10]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes to be ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d0761bf8b0e60b55728ba5981db176f",
     "grade": false,
     "grade_id": "cell-15b052b156ee3862",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (group1): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (conv1): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (skip_conv): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip_batch): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (skip_conv): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip_batch): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (group2): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (conv1): Conv2d(20, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batch1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (skip_conv): Conv2d(20, 40, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (skip_batch): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (skip_conv): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip_batch): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (group3): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batch1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (skip_conv): Conv2d(40, 40, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (skip_batch): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batch2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (skip_conv): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (skip_batch): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us print the architecture of the network\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71ad23804ee4f20b1aa0ff5499a14dae",
     "grade": false,
     "grade_id": "cell-9de9a4ddf89efc42",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us now train the ResNet using the same training loop\n",
    "n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "net = ResNet(n_blocks, n_channels=16)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58659a9b7f0f1499637f04664e6db398",
     "grade": false,
     "grade_id": "cell-50efe3e46b071ec9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.811\n",
      "[1,   400] loss: 0.543\n",
      "[1,   600] loss: 0.444\n",
      "[1,   800] loss: 0.425\n",
      "[1,  1000] loss: 0.380\n",
      "[1,  1200] loss: 0.368\n",
      "[1,  1400] loss: 0.353\n",
      "[1,  1600] loss: 0.356\n",
      "[1,  1800] loss: 0.330\n",
      "Accuracy of the network on the test images: 0.880\n",
      "[2,   200] loss: 0.406\n",
      "[2,   400] loss: 0.335\n",
      "[2,   600] loss: 0.308\n",
      "[2,   800] loss: 0.338\n",
      "[2,  1000] loss: 0.300\n",
      "[2,  1200] loss: 0.314\n",
      "[2,  1400] loss: 0.297\n",
      "[2,  1600] loss: 0.286\n",
      "[2,  1800] loss: 0.301\n",
      "Accuracy of the network on the test images: 0.888\n",
      "[3,   200] loss: 0.274\n",
      "[3,   400] loss: 0.282\n",
      "[3,   600] loss: 0.271\n",
      "[3,   800] loss: 0.257\n",
      "[3,  1000] loss: 0.265\n",
      "[3,  1200] loss: 0.257\n",
      "[3,  1400] loss: 0.270\n",
      "[3,  1600] loss: 0.278\n",
      "[3,  1800] loss: 0.243\n",
      "Accuracy of the network on the test images: 0.896\n",
      "[4,   200] loss: 0.236\n",
      "[4,   400] loss: 0.253\n",
      "[4,   600] loss: 0.253\n",
      "[4,   800] loss: 0.240\n",
      "[4,  1000] loss: 0.250\n",
      "[4,  1200] loss: 0.232\n",
      "[4,  1400] loss: 0.249\n",
      "[4,  1600] loss: 0.242\n",
      "[4,  1800] loss: 0.246\n",
      "Accuracy of the network on the test images: 0.894\n",
      "[5,   200] loss: 0.214\n",
      "[5,   400] loss: 0.216\n",
      "[5,   600] loss: 0.203\n",
      "[5,   800] loss: 0.227\n",
      "[5,  1000] loss: 0.219\n",
      "[5,  1200] loss: 0.232\n",
      "[5,  1400] loss: 0.217\n",
      "[5,  1600] loss: 0.225\n",
      "[5,  1800] loss: 0.225\n",
      "Accuracy of the network on the test images: 0.910\n",
      "[6,   200] loss: 0.197\n",
      "[6,   400] loss: 0.210\n",
      "[6,   600] loss: 0.214\n",
      "[6,   800] loss: 0.212\n",
      "[6,  1000] loss: 0.207\n",
      "[6,  1200] loss: 0.210\n",
      "[6,  1400] loss: 0.211\n",
      "[6,  1600] loss: 0.198\n",
      "[6,  1800] loss: 0.207\n",
      "Accuracy of the network on the test images: 0.912\n",
      "[7,   200] loss: 0.184\n",
      "[7,   400] loss: 0.187\n",
      "[7,   600] loss: 0.182\n",
      "[7,   800] loss: 0.182\n",
      "[7,  1000] loss: 0.201\n",
      "[7,  1200] loss: 0.197\n",
      "[7,  1400] loss: 0.197\n",
      "[7,  1600] loss: 0.203\n",
      "[7,  1800] loss: 0.192\n",
      "Accuracy of the network on the test images: 0.910\n",
      "[8,   200] loss: 0.169\n",
      "[8,   400] loss: 0.168\n",
      "[8,   600] loss: 0.184\n",
      "[8,   800] loss: 0.187\n",
      "[8,  1000] loss: 0.180\n",
      "[8,  1200] loss: 0.179\n",
      "[8,  1400] loss: 0.190\n",
      "[8,  1600] loss: 0.196\n",
      "[8,  1800] loss: 0.183\n",
      "Accuracy of the network on the test images: 0.913\n",
      "[9,   200] loss: 0.147\n",
      "[9,   400] loss: 0.160\n",
      "[9,   600] loss: 0.191\n",
      "[9,   800] loss: 0.172\n",
      "[9,  1000] loss: 0.174\n",
      "[9,  1200] loss: 0.165\n",
      "[9,  1400] loss: 0.170\n",
      "[9,  1600] loss: 0.179\n",
      "[9,  1800] loss: 0.183\n",
      "Accuracy of the network on the test images: 0.912\n",
      "[10,   200] loss: 0.142\n",
      "[10,   400] loss: 0.168\n",
      "[10,   600] loss: 0.153\n",
      "[10,   800] loss: 0.161\n",
      "[10,  1000] loss: 0.156\n",
      "[10,  1200] loss: 0.159\n",
      "[10,  1400] loss: 0.162\n",
      "[10,  1600] loss: 0.169\n",
      "[10,  1800] loss: 0.151\n",
      "Accuracy of the network on the test images: 0.907\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200  # mini-batches\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        # Transfer to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1):\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if skip_training:\n",
    "            break\n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "    # Print accuracy after every epoch\n",
    "    accuracy = compute_accuracy(net, testloader)\n",
    "    print('Accuracy of the network on the test images: %.3f' % accuracy)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08941fbd2953e25da378c4226c5a6488",
     "grade": false,
     "grade_id": "cell-6b2ab46dba3aa322",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You should get the test accuracy at about 90-91%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69ea9b19ef5263efed4c58b3db96cf23",
     "grade": true,
     "grade_id": "cell-cd608a7294f2ceb6",
     "locked": true,
     "points": 0.001,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 4_resnet.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the network to a file, submit this file together with your notebook\n",
    "filename = '4_resnet.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(net.state_dict(), filename)\n",
    "            print('Model saved to %s' % filename)\n",
    "        else:\n",
    "            print('Model not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
    "else:\n",
    "    net = ResNet(n_blocks, n_channels=16)\n",
    "    net.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    net.to(device)\n",
    "    print('Model loaded from %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f420b734e91bcc49286c70c043995b25",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 0.907\n"
     ]
    }
   ],
   "source": [
    "# Let us compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print('Accuracy of the network on the test images: %.3f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
