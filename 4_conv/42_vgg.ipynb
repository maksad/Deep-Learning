{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a7979e8caaaed8a717e326be94fd4f6",
     "grade": false,
     "grade_id": "cell-440df6cfa709812f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 4. Convolutional networks\n",
    "\n",
    "## Part 2. VGG-style network\n",
    "\n",
    "In the second part you need to train a convolutional neural network with an architecture inspired by a VGG-network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5dbff9bac5479ad10101fdef6a7c2a7",
     "grade": false,
     "grade_id": "cell-902667dea4d68204",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Select data directory\n",
    "import os\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e0d4635b5905e98963ce92fbfb03375",
     "grade": false,
     "grade_id": "cell-d1a0f2d597ac9692",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d33ffe246f5459117f53cac15b370d",
     "grade": false,
     "grade_id": "cell-fe95dcf02c6b9c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05dae4d3d681cf9666b90ac940628a83",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(course_data_dir, 'fashion_mnist')\n",
    "print('Data stored in %s' % data_dir)\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c554ba5450d41d232bee8a726dca64aa",
     "grade": false,
     "grade_id": "cell-b107418d64770e19",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eccfe8c399d71b5018afc8ef3b0e9132",
     "grade": false,
     "grade_id": "cell-4ab9d042e4edcd54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# VGG-style network\n",
    "\n",
    "Let us now define a convolution neural network with an architecture inspired by the [VGG-net](https://arxiv.org/abs/1409.1556):\n",
    "\n",
    "<img src=\"vgg-style.png\" width=600 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "370a1bed1c0c4513b020e335db599149",
     "grade": false,
     "grade_id": "cell-91295b0ab2098018",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The architecture:\n",
    "* A block of three convolutional layers with:\n",
    "    * 3x3 kernel\n",
    "    * 16 output channels\n",
    "    * one pixel zero-pading on both sides\n",
    "    * 2d batch normalization after each convolutional layer\n",
    "    * ReLU nonlinearity\n",
    "* Max pooling layer with 2x2 kernel and stride 2.\n",
    "* A block of three convolutional layers with:\n",
    "    * 3x3 kernel\n",
    "    * 32 output channels\n",
    "    * one pixel zero-pading on both sides\n",
    "    * 2d batch normalization after each convolutional layer\n",
    "    * ReLU nonlinearity\n",
    "* Max pooling layer with 2x2 kernel and stride 2.\n",
    "* One convolutional layer with:\n",
    "    * 3x3 kernel\n",
    "    * 48 output channels\n",
    "    * *no padding*\n",
    "    * 2d batch normalization after the convolutional layer\n",
    "    * ReLU nonlinearity\n",
    "* One convolutional layer with:\n",
    "    * 1x1 kernel\n",
    "    * 32 output channels\n",
    "    * *no padding*\n",
    "    * 2d batch normalization after the convolutional layer\n",
    "    * ReLU nonlinearity\n",
    "* One convolutional layer with:\n",
    "    * 1x1 kernel\n",
    "    * 16 output channels\n",
    "    * *no padding*\n",
    "    * 2d batch normalization after the convolutional layer\n",
    "    * ReLU nonlinearity\n",
    "* Global average pooling:\n",
    "    * 5x5 kernel (the input of the layer should be 5x5)\n",
    "* A fully-connected layer with 10 outputs (no nonlinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d524906ba4a26f1dec8c0e325893d21",
     "grade": false,
     "grade_id": "cell-958d9ce586a51bd3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, n_channels=16):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_channels (int): Number of channels in the first convolutional layer. The number of channels in the\n",
    "                             following layers are the multipliers of n_channels.\n",
    "        \"\"\"\n",
    "        super(VGGNet, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"You can (optionally) print the shapes of the intermediate variables with verbose=True.\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the shapes of the tensors\n",
    "net = VGGNet()\n",
    "net.to(device)\n",
    "\n",
    "# Feed a batch of images from the training data to test the network\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.to(device)\n",
    "    print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "    y = net(images, verbose=True)\n",
    "    assert y.shape == torch.Size([32, 10]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes seem to be ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "439bd75312c86cecd1d5af1d8a8b6760",
     "grade": true,
     "grade_id": "architecture_soft",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a cell used for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "375155e105b5dd7a4cf45f2e4b1c5405",
     "grade": true,
     "grade_id": "architecture_hard",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a cell used for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cc9be08ff34d62640091085d6cbce15",
     "grade": false,
     "grade_id": "cell-7e781e592e778a97",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Now let us train the network using the same training loop\n",
    "net = VGGNet()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6e85b0f9e5de8c74ee0871f927810e4",
     "grade": false,
     "grade_id": "cell-c872a03d9a23c7d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31143e4e2ef6266917e7181733bd6111",
     "grade": false,
     "grade_id": "training_loop",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200  # mini-batches\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        # Transfer to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1):\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "        if skip_training:\n",
    "            break\n",
    "\n",
    "    # Print accuracy after every epoch\n",
    "    accuracy = compute_accuracy(net, testloader)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * accuracy))\n",
    "\n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac20170c5701923a114407c375033e5f",
     "grade": false,
     "grade_id": "cell-ce7291729e25c18d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You should get the test accuracy slightly better than the accuracy of a simple conv net from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a2b0fdf37f54595b6395b0946bdcc5b",
     "grade": true,
     "grade_id": "save",
     "locked": true,
     "points": 0.001,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the network to a file, submit this file together with your notebook\n",
    "filename = '4_vgg_net.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(net.state_dict(), filename)\n",
    "            print('Model saved to %s' % filename)\n",
    "        else:\n",
    "            print('Model not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
    "else:\n",
    "    net = VGGNet()\n",
    "    net.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    net.to(device)\n",
    "    print('Model loaded from %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9663db7adfa1142b25e40d1b03003d8d",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print('Accuracy of the VGG net on the test images: %.3f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
